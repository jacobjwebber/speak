{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Room acoustics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic theory\n",
    "\n",
    "The rooms in which we perceive sound affect the sound we hear.\n",
    "\n",
    "There is a sound source and an observer\n",
    "\n",
    "Sound is released from source in all directions, a direct line reaches the observer, followed by reflections off walls and other objects.\n",
    "\n",
    "You can model this with ray-tracing\n",
    "(ignores refraction and other wave effects, FD-TD methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Time-Invariance\n",
    "\n",
    "Because this model treats room acoustical responses as a set of delay lines depending on path taken from source -> reflections -> observer it is _linear time-invariant_\n",
    "\n",
    "### Linearity\n",
    "\n",
    "The linear aspect of this means the following two properties hold [source](https://ccrma.stanford.edu/~jos/fp/Superposition.html)\n",
    "\n",
    "Superposition:\n",
    "\n",
    "    When two signals are added together and fed to the filter, the filter output is the same as if one had put each signal through the filter separately and then added the outputs (the superposition property). \n",
    "    \n",
    "Scaling:\n",
    "\n",
    "    The amplitude of the output is proportional to the amplitude of the input (the scaling property).\n",
    "\n",
    "### Time invariant \n",
    "Means that the system will not change with time. A sound delayed by N samples will have an output after being recorded in the room that's the same other than also being delayed by N samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LTI systems and convolution\n",
    "\n",
    "Importantly (as noted in first para of wikipedia page on LTI systems)\n",
    "\n",
    "the response $y(t)$ of the system to an arbitrary input $x(t)$ can be found directly using convolution: $y(t) = x(t) ∗ h(t)$ where h(t) is called the system's impulse response and $∗$ represents convolution\n",
    "\n",
    "This means (because of convolution theory) an LTI system will only rescale individual magnitude and phase components of the Fourier transform of a signal, and will have a _frequency response_ defined by the Fourier transform of the impulse response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import scipy\n",
    "import librosa.display\n",
    "\n",
    "x = np.array([1.,0.,0.,0.,0.])\n",
    "X = np.fft.fft(x)\n",
    "np.abs(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reverberation Time\n",
    "\n",
    "The amount of time it takes for a reverbed signal to drop by 60dB (1/1000) ($T_60$)\n",
    "\n",
    "How echo-y a room sounds. Varies by frequency but we take an average.\n",
    "\n",
    "Concert hall ~2s\n",
    "St Pauls 11s or 8s\n",
    "\n",
    "Exponential decay a rough approximation for impulse response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Fs = 22050\n",
    "\n",
    "def exp_decay(reverb_time, T, ratio=10e-6):\n",
    "    a = -np.log(ratio)\n",
    "    t = np.linspace(0, T, int(T*Fs))\n",
    "    return np.exp(-a*t/reverb_time)\n",
    "\n",
    "concert_hall_ir = exp_decay(2,4)\n",
    "st_pauls_ir = exp_decay(12,4)\n",
    "\n",
    "plt.plot(np.linspace(0, 4, int(4*Fs)), concert_hall_ir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can now convolve these with our 'dry' source signal (recorded in a not-very-reverberant room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y, sr = librosa.load('reverb_source.wav',sr=Fs)\n",
    "\n",
    "st_p = scipy.signal.convolve(y, 1*st_pauls_ir)\n",
    "ipd.Audio(st_p, rate=Fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measuring real-world impulse responses\n",
    "\n",
    "We can also measure real-world impulses responses\n",
    "\n",
    "Crudely: by clapping or bursting a balloon\n",
    "\n",
    "Accurately: with a 'chirp' signal (see Aurora plugin for Audacity).\n",
    "\n",
    "I recorded myself clapping in an echo-y office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "office_ir, _ = librosa.load('impulse_response_office.wav', sr=Fs)\n",
    "ipd.Audio(office_ir, rate=Fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "office_output = scipy.signal.convolve(y, office_ir)\n",
    "ipd.Audio(office_output, rate=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can compare this with a ground truth recording I made in the same room (where I tried to recreate my previous intonation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "office_gt, _ = librosa.load('office_ground_truth.wav')\n",
    "ipd.Audio(office_gt, rate=Fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Lets try the same in this room!\n",
    "\n",
    "imr_ir, _ = librosa.load('imr_impulse_response.wav',sr=Fs)\n",
    "imr_output = scipy.signal.convolve(y, imr_ir)\n",
    "ipd.Audio(office_gt, rate=Fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In the frequency domain\n",
    "\n",
    "Convolution is equivalent to element-wise multiplication of the frequency domain signal. This means the effects of room reverb can often be visualised in spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def plot(wave):\n",
    "    D = librosa.stft(wave)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    plt.figure()\n",
    "    librosa.display.specshow(S_db)\n",
    "    plt.colorbar()\n",
    "    \n",
    "plot(office_gt)\n",
    "plot(y)\n",
    "plot(office_output[:len(y)])\n",
    "plot(office_ir)\n",
    "#plt.figure()\n",
    "#plt.plot(np.abs(np.fft.fft(office_ir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
